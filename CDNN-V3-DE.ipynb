{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccae324",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split   \n",
    "#import pickle\n",
    "import math\n",
    "from sklearn import preprocessing \n",
    "\n",
    "#import statements\n",
    "from keras.layers.core import Dense, Activation, Dropout #core layers that used to build the network\n",
    "#M-from keras.layers.recurrent import LSTM,GRU\n",
    "from keras.layers.core import Dense, Activation, Dropout #M\n",
    "from keras.models import Sequential, load_model\n",
    "import time\n",
    "import pandas as pd #define the data structures\n",
    "import matplotlib as plt #for visualization\n",
    "from sklearn.preprocessing import StandardScaler #for normalizing our data(scaling)\n",
    "import numpy as np #for matrix multiplication\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#read the annotated file \n",
    "from math import sqrt\n",
    "from numpy import concatenate \n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error \n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go \n",
    "import seaborn as sns\n",
    "py.init_notebook_mode(connected=True)\n",
    "import os  \n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import numpy\n",
    "numpy.random.seed(2)\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ccbbdb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Admin\\Desktop\\Notepad\\Data\\NNData.csv')\n",
    "df.columns=['p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'p7', 'p8', 'p9', 'p10', 'p11', 'p12', 'p13', 'p14', 'p15', 'p16', 'p17', 'p18', 'p19', 'p20', 'p21', 'p22', 'p23', 'p24', 'p25', 'p26', 'p27', 'p28', 'p29', 'p30', 'p31', 'p32', 'p33', 'p34', 'p35', 'p36', 'p37', 'p38', 'p39', 'p40', 'p41', 'p42', 'p43', 'p44', 'p45', 'p46', 'p47', 'p48', 'p49', 'p50', 'p51', 'p52', 'p53', 'p54', 'p55', 'p56', 'p57', 'p58', 'p59', 'p60', 'p61', 'p62', 'p63', 'p64', 'p65', 'p66', 'p67', 'p68', 'p69', 'p70', 'p71', 'p72', 'p73', 'p74', 'p75', 'p76', 'p77', 'p78', 'p79', 'p80', 'p81', 'p82', 'p83', 'p84', 'p85', 'p86', 'p87', 'p88', 'p89', 'p90', 'p91', 'p92', 'p93', 'p94', 'p95', 'p96', 'p97', 'p98', 'p99', 'p100', 'p101', 'p102', 'p103', 'p104', 'p105', 'p106', 'p107', 'p108', 'p109', 'p110', 'p111', 'p112', 'p113', 'p114', 'p115', 'p116', 'p117', 'p118', 'p119', 'p120', 'p121', 'p122', 'p123', 'p124', 'p125', 'p126', 'p127', 'p128', 'p129', 'p130', 'p131', 'p132', 'p133', 'p134', 'p135', 'p136', 'p137', 'p138', 'p139', 'p140', 'p141', 'p142', 'p143', 'p144', 'p145', 'p146', 'p147', 'p148', 'p149', 'p150', 'p151', 'p152', 'p153', 'p154', 'p155', 'p156', 'p157', 'p158', 'p159', 'p160', 'p161', 'p162', 'p163', 'p164', 'p165', 'p166', 'p167', 'p168', 'p169', 'p170', 'p171', 'p172', 'p173', 'p174', 'p175', 'p176', 'p177', 'p178', 'p179', 'p180', 'p181', 'p182', 'p183', 'p184', 'p185', 'p186', 'p187', 'p188', 'p189', 'p190', 'p191', 'p192', 'p193', 'p194', 'p195', 'p196', 'p197', 'p198', 'p199', 'p200', 'p201', 'p202', 'p203', 'p204', 'p205', 'p206', 'p207', 'p208', 'p209', 'p210', 'p211', 'p212', 'p213', 'p214', 'p215', 'p216', 'p217', 'p218', 'p219', 'p220', 'p221', 'p222', 'p223', 'p224', 'p225', 'p226', 'p227', 'p228', 'p229', 'p230', 'p231', 'p232', 'p233', 'p234', 'p235', 'p236', 'p237', 'p238', 'p239', 'p240', 'p241', 'p242', 'p243', 'p244', 'p245', 'p246', 'p247', 'p248', 'p249', 'p250', 'p251', 'p252', 'p253', 'p254', 'p255', 'p256', 'p257', 'p258', 'p259', 'p260', 'p261', 'p262', 'p263', 'p264', 'p265', 'p266', 'p267', 'p268', 'p269', 'p270', 'p271', 'p272', 'p273', 'p274', 'p275', 'p276', 'p277', 'p278', 'p279', 'p280', 'p281', 'p282', 'p283', 'p284', 'p285', 'p286', 'p287', 'p288', 'p289', 'p290', 'p291', 'p292', 'p293', 'p294', 'p295', 'p296', 'p297', 'p298', 'p299', 'p300', 'p301', 'p302', 'p303', 'p304', 'p305', 'p306', 'p307', 'p308', 'p309', 'p310', 'p311', 'p312', 'p313', 'p314', 'p315', 'p316', 'p317', 'p318', 'p319', 'p320', 'p321', 'p322', 'p323', 'p324', 'p325', 'p326', 'p327', 'p328', 'p329', 'p330', 'p331', 'p332', 'p333', 'p334', 'p335', 'p336', 'p337', 'p338', 'p339', 'p340', 'p341', 'p342', 'p343', 'p344', 'p345', 'p346', 'p347', 'p348', 'p349', 'p350', 'p351', 'p352', 'p353', 'p354', 'p355', 'p356', 'p357', 'p358', 'p359', 'p360', 'p361', 'p362', 'p363', 'p364', 'p365', 'p366', 'p367', 'p368', 'p369', 'p370', 'p371', 'p372', 'p373', 'p374', 'p375', 'p376', 'p377', 'p378', 'p379', 'p380', 'p381', 'p382', 'p383', 'p384', 'p385', 'p386', 'p387', 'p388', 'p389', 'p390', 'p391', 'p392', 'p393', 'p394', 'p395', 'p396', 'p397', 'p398', 'p399', 'p400', 'p401', 'p402', 'p403', 'p404', 'p405', 'p406', 'p407', 'p408', 'p409', 'p410', 'p411', 'p412', 'p413', 'p414', 'p415', 'p416', 'p417', 'p418', 'p419', 'p420', 'p421', 'p422', 'p423', 'p424', 'p425', 'p426', 'p427', 'p428', 'p429', 'p430', 'p431', 'p432', 'p433', 'p434', 'p435', 'p436', 'p437', 'p438', 'p439', 'p440', 'p441', 'p442', 'p443', 'p444', 'p445', 'p446', 'p447', 'p448', 'p449', 'p450', 'p451', 'p452', 'p453', 'p454', 'p455', 'p456', 'p457', 'p458', 'p459', 'p460', 'p461', 'p462', 'p463', 'p464', 'p465', 'p466', 'p467', 'p468', 'p469', 'p470', 'p471', 'p472', 'p473', 'p474', 'p475', 'p476', 'p477', 'p478', 'p479', 'p480', 'p481', 'p482', 'p483', 'p484', 'p485', 'p486', 'p487', 'p488', 'p489', 'p490', 'p491', 'p492', 'p493', 'p494', 'p495', 'p496', 'p497', 'p498', 'p499', 'p500', 'p501', 'p502', 'p503', 'p504', 'p505', 'p506', 'p507', 'p508', 'p509', 'p510', 'p511', 'p512', 'p513', 'p514', 'p515', 'p516', 'p517', 'p518', 'p519', 'p520', 'p521', 'p522', 'p523', 'p524', 'p525', 'p526', 'p527', 'p528', 'p529', 'p530', 'p531', 'p532', 'p533', 'p534', 'p535', 'p536', 'p537', 'p538', 'p539', 'p540', 'p541', 'p542', 'p543', 'p544', 'p545', 'p546', 'p547', 'p548', 'p549', 'p550', 'p551', 'p552', 'p553', 'p554', 'p555', 'p556', 'p557', 'p558', 'p559', 'p560', 'p561', 'p562', 'p563', 'p564', 'p565', 'p566', 'p567', 'p568', 'p569', 'p570', 'p571', 'p572', 'p573', 'p574', 'p575', 'p576', 'p577', 'p578', 'p579', 'p580', 'p581', 'p582', 'p583', 'p584', 'p585', 'p586', 'p587', 'p588', 'p589', 'p590', 'p591', 'p592', 'p593', 'p594', 'p595', 'p596', 'p597', 'p598', 'p599', 'p600', 'p601', 'p602', 'p603', 'p604', 'p605', 'p606', 'p607', 'p608', 'p609', 'p610', 'p611', 'p612', 'p613', 'p614', 'p615', 'p616', 'p617', 'p618', 'p619', 'p620', 'p621', 'p622', 'p623', 'p624', 'p625', 'p626', 'p627', 'p628', 'p629', 'p630', 'p631', 'p632', 'p633', 'p634', 'p635', 'p636', 'p637', 'p638', 'p639', 'p640', 'p641', 'p642', 'p643', 'p644', 'p645', 'p646', 'p647', 'p648', 'p649', 'p650', 'p651', 'p652', 'p653', 'p654', 'p655', 'p656', 'p657', 'p658', 'p659', 'p660', 'p661', 'p662', 'p663', 'p664', 'p665', 'p666', 'p667', 'p668', 'p669', 'p670', 'p671', 'p672', 'p673', 'p674', 'p675', 'p676', 'p677', 'p678', 'p679', 'p680', 'p681', 'p682', 'p683', 'p684', 'p685', 'p686', 'p687', 'p688', 'p689', 'p690', 'p691', 'p692', 'p693', 'p694', 'p695', 'p696', 'p697', 'p698', 'p699', 'p700', 'p701', 'p702', 'p703', 'p704', 'p705', 'p706', 'p707', 'p708', 'p709', 'p710', 'p711', 'p712', 'p713', 'p714', 'p715', 'p716', 'p717', 'p718', 'p719', 'p720', 'p721', 'p722', 'p723', 'p724', 'p725', 'p726', 'p727', 'p728', 'p729', 'p730', 'p731', 'p732', 'p733', 'p734', 'p735', 'p736', 'p737', 'p738', 'p739', 'p740', 'p741', 'p742', 'p743', 'p744', 'p745', 'p746', 'p747', 'p748', 'p749', 'p750', 'p751', 'p752', 'p753', 'p754', 'p755', 'p756', 'p757', 'p758', 'p759', 'p760', 'p761', 'p762', 'p763', 'p764', 'p765', 'p766', 'p767', 'p768', 'p769', 'p770', 'p771', 'p772', 'p773', 'p774', 'p775', 'p776', 'p777', 'p778', 'p779', 'p780', 'p781', 'p782', 'p783', 'p784', 'p785', 'p786', 'p787', 'p788', 'p789', 'p790', 'p791', 'p792', 'p793', 'p794', 'p795', 'p796', 'p797', 'p798', 'p799', 'p800', 'p801', 'p802', 'p803', 'p804', 'p805', 'p806', 'p807', 'p808', 'p809', 'p810', 'p811', 'p812', 'p813', 'p814', 'p815', 'p816', 'p817', 'p818', 'p819', 'p820', 'p821', 'p822', 'p823', 'p824', 'p825', 'p826', 'p827', 'p828', 'p829', 'p830', 'p831', 'p832', 'p833', 'p834', 'p835', 'p836', 'p837', 'p838', 'p839', 'p840', 'p841', 'p842', 'p843', 'p844', 'p845', 'p846', 'p847', 'p848', 'p849', 'p850', 'p851', 'p852', 'p853', 'p854', 'p855', 'p856', 'p857', 'p858', 'p859', 'p860', 'p861', 'p862', 'p863', 'p864', 'p865', 'p866', 'p867', 'p868', 'p869', 'p870', 'p871', 'p872', 'p873', 'p874', 'p875', 'p876', 'p877', 'p878', 'p879', 'p880', 'p881', 'p882', 'p883', 'p884', 'p885', 'p886', 'p887', 'p888', 'p889', 'p890', 'p891', 'p892', 'p893', 'p894', 'p895', 'p896', 'p897', 'p898', 'p899', 'p900', 'p901', 'p902', 'p903', 'p904', 'p905', 'p906', 'p907', 'p908', 'p909', 'p910', 'p911', 'p912', 'p913', 'p914', 'p915', 'p916', 'p917', 'p918', 'p919', 'p920', 'p921', 'p922', 'p923', 'p924', 'p925', 'p926', 'p927', 'p928', 'p929', 'p930', 'p931', 'p932', 'p933', 'p934', 'p935', 'p936', 'p937', 'p938', 'p939', 'p940', 'p941', 'p942', 'p943', 'p944', 'p945', 'p946', 'p947', 'p948', 'p949', 'p950', 'p951', 'p952', 'p953', 'p954', 'p955', 'p956', 'p957', 'p958', 'p959', 'p960', 'p961', 'p962', 'p963', 'p964', 'p965', 'p966', 'p967', 'p968', 'p969', 'p970', 'p971', 'p972', 'p973', 'p974', 'p975', 'p976', 'p977', 'p978', 'p979', 'p980', 'p981', 'p982', 'p983', 'p984', 'p985', 'p986', 'p987', 'p988', 'p989', 'p990', 'p991', 'p992', 'p993', 'p994', 'p995', 'p996', 'p997', 'p998', 'p999', 'p1000', 'p1001', 'p1002', 'p1003', 'p1004', 'p1005', 'p1006', 'p1007', 'p1008', 'p1009', 'p1010', 'p1011', 'p1012', 'p1013', 'p1014', 'p1015', 'p1016', 'p1017', 'p1018', 'p1019', 'p1020', 'p1021', 'p1022', 'p1023', 'p1024', 'p1025', 'p1026', 'p1027', 'p1028', 'p1029', 'p1030', 'p1031', 'p1032', 'p1033', 'p1034', 'p1035', 'p1036', 'p1037', 'p1038', 'p1039', 'p1040', 'p1041', 'p1042', 'p1043', 'p1044', 'p1045', 'p1046', 'p1047', 'p1048', 'p1049', 'p1050', 'p1051', 'p1052', 'p1053', 'p1054', 'p1055', 'p1056', 'p1057', 'p1058', 'p1059', 'p1060', 'p1061', 'p1062', 'p1063', 'p1064', 'p1065', 'p1066', 'p1067', 'p1068', 'p1069', 'p1070', 'p1071', 'p1072', 'p1073', 'p1074', 'p1075', 'p1076', 'p1077', 'p1078', 'p1079', 'p1080', 'p1081', 'p1082', 'p1083', 'p1084', 'p1085', 'p1086', 'p1087', 'p1088', 'p1089', 'p1090', 'p1091', 'p1092', 'p1093', 'p1094', 'p1095', 'p1096', 'p1097', 'p1098', 'p1099', 'p1100', 'p1101', 'p1102', 'p1103', 'p1104', 'p1105', 'p1106', 'p1107', 'p1108', 'p1109', 'p1110', 'p1111', 'p1112', 'p1113', 'p1114', 'p1115', 'p1116', 'p1117', 'p1118', 'p1119', 'p1120', 'p1121', 'p1122', 'p1123', 'p1124', 'p1125', 'p1126', 'p1127', 'p1128', 'p1129', 'p1130', 'p1131', 'p1132', 'p1133', 'p1134', 'p1135', 'p1136', 'p1137', 'p1138', 'p1139', 'p1140', 'p1141', 'p1142', 'p1143', 'p1144', 'p1145', 'p1146', 'p1147', 'p1148', 'p1149', 'p1150', 'p1151', 'p1152', 'p1153', 'p1154', 'p1155', 'p1156', 'p1157', 'p1158', 'p1159', 'p1160', 'p1161', 'p1162', 'p1163', 'p1164', 'p1165', 'p1166', 'p1167', 'p1168', 'p1169', 'p1170', 'p1171', 'p1172', 'p1173', 'p1174', 'p1175', 'p1176', 'p1177', 'p1178', 'p1179', 'p1180', 'p1181', 'p1182', 'p1183', 'p1184', 'p1185', 'p1186', 'p1187', 'p1188', 'p1189', 'p1190', 'p1191', 'p1192', 'p1193', 'p1194', 'p1195', 'p1196', 'p1197', 'p1198', 'p1199', 'p1200', 'p1201', 'p1202', 'p1203', 'p1204', 'p1205', 'p1206', 'p1207', 'p1208', 'p1209', 'p1210', 'p1211', 'p1212', 'p1213', 'p1214', 'p1215', 'p1216', 'p1217', 'p1218', 'p1219', 'p1220', 'p1221', 'p1222', 'p1223', 'p1224', 'p1225', 'p1226', 'p1227', 'p1228', 'p1229', 'p1230', 'p1231', 'p1232', 'p1233', 'p1234', 'p1235', 'p1236', 'p1237', 'p1238', 'p1239', 'p1240', 'p1241', 'p1242', 'p1243', 'p1244', 'p1245', 'p1246', 'p1247', 'p1248', 'p1249', 'p1250', 'p1251', 'p1252', 'p1253', 'p1254', 'p1255', 'p1256', 'p1257', 'p1258', 'p1259', 'p1260', 'p1261', 'p1262', 'p1263', 'p1264', 'p1265', 'p1266', 'p1267', 'p1268', 'p1269', 'p1270', 'p1271', 'p1272', 'p1273', 'p1274', 'p1275', 'p1276', 'p1277', 'p1278', 'p1279', 'p1280', 'p1281', 'p1282', 'p1283', 'p1284', 'p1285', 'p1286', 'p1287', 'p1288', 'p1289', 'p1290', 'p1291', 'p1292', 'p1293', 'p1294', 'p1295', 'p1296', 'p1297', 'p1298', 'p1299', 'p1300', 'p1301', 'p1302', 'p1303', 'p1304', 'p1305', 'p1306', 'p1307', 'p1308', 'p1309', 'p1310', 'p1311', 'p1312', 'p1313', 'p1314', 'p1315', 'p1316', 'p1317', 'p1318', 'p1319', 'p1320', 'p1321', 'p1322', 'p1323', 'p1324', 'p1325', 'p1326', 'p1327', 'p1328', 'p1329', 'p1330', 'p1331', 'p1332', 'p1333', 'p1334', 'p1335', 'p1336', 'p1337', 'p1338', 'p1339', 'p1340', 'p1341', 'p1342', 'p1343', 'p1344', 'p1345', 'p1346', 'p1347', 'p1348', 'p1349', 'p1350', 'p1351', 'p1352', 'p1353', 'p1354', 'p1355', 'p1356', 'p1357', 'p1358', 'p1359', 'p1360', 'p1361', 'p1362', 'p1363', 'p1364', 'p1365', 'p1366', 'p1367', 'p1368', 'p1369', 'p1370', 'p1371', 'p1372', 'p1373', 'p1374', 'p1375', 'p1376', 'p1377', 'p1378', 'p1379', 'p1380', 'p1381', 'p1382', 'p1383', 'p1384', 'p1385', 'p1386', 'p1387', 'p1388', 'p1389', 'p1390', 'p1391', 'p1392', 'p1393', 'p1394', 'p1395', 'p1396', 'p1397', 'p1398', 'p1399', 'p1400', 'p1401', 'p1402', 'p1403', 'p1404', 'p1405', 'p1406', 'p1407', 'p1408', 'p1409', 'p1410', 'p1411', 'p1412', 'p1413', 'p1414', 'p1415', 'p1416', 'p1417', 'p1418', 'p1419', 'p1420', 'p1421', 'p1422', 'p1423', 'p1424', 'p1425', 'p1426', 'p1427', 'p1428', 'p1429', 'p1430', 'p1431', 'p1432', 'p1433', 'p1434', 'p1435', 'p1436', 'p1437', 'p1438', 'p1439', 'p1440', 'p1441', 'p1442', 'p1443', 'p1444', 'p1445', 'p1446', 'p1447', 'p1448', 'p1449', 'p1450', 'p1451', 'p1452', 'p1453', 'p1454', 'p1455', 'p1456', 'p1457', 'p1458', 'p1459', 'p1460', 'p1461', 'p1462', 'p1463', 'p1464', 'p1465', 'p1466', 'p1467', 'p1468', 'p1469', 'p1470', 'p1471', 'p1472', 'p1473', 'p1474', 'p1475', 'p1476', 'p1477', 'p1478', 'p1479', 'p1480', 'p1481', 'p1482', 'p1483', 'p1484', 'p1485', 'p1486', 'p1487', 'p1488', 'p1489', 'p1490', 'p1491', 'p1492', 'p1493', 'p1494', 'p1495', 'p1496', 'p1497', 'p1498', 'p1499', 'p1500', 'p1501', 'p1502', 'p1503', 'p1504', 'p1505', 'p1506', 'p1507', 'p1508', 'p1509', 'p1510', 'p1511', 'p1512', 'p1513', 'p1514', 'p1515', 'p1516', 'p1517', 'p1518', 'p1519', 'p1520', 'p1521', 'p1522', 'p1523', 'p1524', 'p1525', 'p1526', 'p1527', 'p1528', 'p1529', 'p1530', 'p1531', 'p1532', 'p1533', 'p1534', 'p1535', 'p1536', 'p1537', 'p1538', 'p1539', 'p1540', 'p1541', 'p1542', 'p1543', 'p1544', 'p1545', 'p1546', 'p1547', 'p1548', 'p1549', 'p1550', 'p1551', 'p1552', 'p1553', 'p1554', 'p1555', 'p1556', 'p1557', 'p1558', 'p1559', 'p1560', 'p1561', 'p1562', 'p1563', 'p1564', 'p1565', 'p1566', 'p1567', 'p1568', 'p1569', 'p1570', 'p1571', 'p1572', 'p1573', 'p1574', 'p1575', 'p1576', 'p1577', 'p1578', 'p1579', 'p1580', 'p1581', 'p1582', 'p1583', 'p1584', 'p1585', 'p1586', 'p1587', 'p1588', 'p1589', 'p1590', 'p1591', 'p1592', 'p1593', 'p1594', 'p1595', 'p1596', 'p1597', 'p1598', 'p1599', 'p1600', 'p1601', 'p1602', 'p1603', 'p1604', 'p1605', 'p1606', 'p1607', 'p1608', 'p1609', 'p1610', 'p1611', 'p1612', 'p1613', 'p1614', 'p1615', 'p1616', 'p1617', 'p1618', 'p1619', 'p1620', 'p1621', 'p1622', 'p1623', 'p1624', 'p1625', 'p1626', 'p1627', 'p1628', 'p1629', 'p1630', 'p1631', 'p1632', 'p1633', 'p1634', 'p1635', 'p1636', 'p1637', 'p1638', 'p1639', 'p1640', 'p1641', 'p1642', 'p1643', 'p1644', 'p1645', 'p1646', 'p1647', 'p1648', 'p1649', 'p1650', 'p1651', 'p1652', 'p1653', 'p1654', 'p1655', 'p1656', 'p1657', 'p1658', 'p1659', 'p1660', 'p1661', 'p1662', 'p1663', 'p1664', 'p1665', 'p1666', 'p1667', 'p1668', 'p1669', 'p1670', 'p1671', 'p1672', 'p1673', 'p1674', 'p1675', 'p1676', 'p1677', 'p1678', 'p1679', 'p1680', 'p1681', 'p1682', 'p1683', 'p1684', 'p1685', 'p1686', 'p1687', 'p1688', 'p1689', 'p1690', 'p1691', 'p1692', 'p1693', 'p1694', 'p1695', 'p1696', 'p1697', 'p1698', 'p1699', 'p1700', 'p1701', 'p1702', 'p1703', 'p1704', 'p1705', 'p1706', 'p1707', 'p1708', 'p1709', 'p1710', 'p1711', 'p1712', 'p1713', 'p1714', 'p1715', 'p1716', 'p1717', 'p1718', 'p1719', 'p1720', 'p1721', 'p1722', 'p1723', 'p1724', 'p1725', 'p1726', 'p1727', 'p1728', 'p1729', 'p1730', 'p1731', 'p1732', 'p1733', 'p1734', 'p1735', 'p1736', 'p1737', 'p1738', 'p1739', 'p1740', 'p1741', 'p1742', 'p1743', 'p1744', 'p1745', 'p1746', 'p1747', 'p1748', 'p1749', 'p1750', 'p1751', 'p1752', 'p1753', 'p1754', 'p1755', 'p1756', 'p1757', 'p1758', 'p1759', 'p1760', 'p1761', 'p1762', 'p1763', 'p1764', 'p1765', 'p1766', 'p1767', 'p1768', 'p1769', 'p1770', 'p1771', 'p1772', 'p1773', 'p1774', 'p1775', 'p1776', 'p1777', 'p1778', 'p1779', 'p1780', 'p1781', 'p1782', 'p1783', 'p1784', 'p1785', 'p1786', 'p1787', 'p1788', 'p1789', 'p1790', 'p1791', 'p1792', 'p1793', 'p1794', 'p1795', 'p1796', 'p1797', 'p1798', 'p1799', 'p1800', 'p1801', 'p1802', 'p1803', 'p1804', 'p1805', 'p1806', 'p1807', 'p1808', 'p1809', 'p1810', 'p1811', 'p1812', 'p1813', 'p1814', 'p1815', 'p1816', 'p1817', 'p1818', 'p1819', 'p1820', 'p1821', 'p1822', 'p1823', 'p1824', 'p1825', 'p1826', 'p1827', 'p1828', 'p1829', 'p1830', 'p1831', 'p1832', 'p1833', 'p1834', 'p1835', 'p1836', 'p1837', 'p1838', 'p1839', 'p1840', 'p1841', 'p1842', 'p1843', 'p1844', 'p1845', 'p1846', 'p1847', 'p1848', 'p1849', 'p1850', 'p1851', 'p1852', 'p1853', 'p1854', 'p1855', 'p1856', 'p1857', 'p1858', 'p1859', 'p1860', 'p1861', 'p1862', 'p1863', 'p1864', 'p1865', 'p1866', 'p1867', 'p1868', 'p1869', 'p1870', 'p1871', 'p1872', 'p1873', 'p1874', 'p1875', 'p1876', 'p1877', 'p1878', 'p1879', 'p1880', 'p1881', 'p1882', 'p1883', 'p1884', 'p1885', 'p1886', 'p1887', 'p1888', 'p1889', 'p1890', 'p1891', 'p1892', 'p1893', 'p1894', 'p1895', 'p1896', 'p1897', 'p1898', 'p1899', 'p1900', 'p1901', 'p1902', 'p1903', 'p1904', 'p1905', 'p1906', 'p1907', 'p1908', 'p1909', 'p1910', 'p1911', 'p1912', 'p1913', 'p1914', 'p1915', 'p1916', 'p1917', 'p1918', 'p1919', 'p1920', 'p1921', 'p1922', 'p1923', 'p1924', 'p1925', 'p1926', 'p1927', 'p1928', 'p1929', 'p1930', 'p1931', 'p1932', 'p1933', 'p1934', 'p1935', 'p1936', 'p1937', 'p1938', 'p1939', 'p1940', 'p1941', 'p1942', 'p1943', 'p1944', 'p1945', 'p1946', 'p1947', 'p1948', 'p1949', 'p1950', 'p1951', 'p1952', 'p1953', 'p1954', 'p1955', 'p1956', 'p1957', 'p1958', 'p1959', 'p1960', 'p1961', 'p1962', 'p1963', 'p1964', 'p1965', 'p1966', 'p1967', 'p1968', 'p1969', 'p1970', 'p1971', 'p1972', 'p1973', 'p1974', 'p1975', 'p1976', 'p1977', 'p1978', 'p1979', 'p1980', 'p1981', 'p1982', 'p1983', 'p1984', 'p1985', 'p1986', 'p1987', 'p1988', 'p1989', 'p1990', 'p1991', 'p1992', 'p1993', 'p1994', 'p1995', 'p1996', 'p1997', 'p1998', 'p1999', 'p2000', 'p2001','FBG1','FBG2','FBG3']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f521c201",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a8cec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Min Max Normalization\n",
    "X=df.iloc[:,:-3]\n",
    "Y=df.iloc[:,-3:]\n",
    "\n",
    "# conversion to numpy array\n",
    "x, y = X.values, Y.values  \n",
    "#print(y)\n",
    "\n",
    "# scaling values for model\n",
    "x_scale = MinMaxScaler(feature_range=(0, 1))\n",
    "y_scale = MinMaxScaler(feature_range=(0, 1)) \n",
    "\n",
    "\n",
    "X = x_scale.fit_transform(x)\n",
    "Y = y_scale.fit_transform(y)   \n",
    "\n",
    "print(len(X),len(Y))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25) \n",
    "print(X_train.shape,X_test.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab25c3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#^X Train    ^X Test   ^Y Train   ^Y Test  \n",
    "# y_train=y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f921f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "class FBGCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FBGCNN, self).__init__()\n",
    "\n",
    "        # 59049 x 1\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, kernel_size=3, stride=1, padding=0),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        # 19683 x 128\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3, stride=3))\n",
    "        # 6561 x 128\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3,stride=3))\n",
    "        # 2187 x 128\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3,stride=3))\n",
    "        # 729 x 256\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3,stride=3))\n",
    "        # 243 x 256\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3,stride=3),\n",
    "            nn.Dropout(0.5))\n",
    "        # 81 x 256\n",
    "        self.conv7 = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3,stride=3))\n",
    "        # 27 x 256\n",
    "        self.conv8 = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3,stride=3))\n",
    "        # 9 x 256\n",
    "        self.conv9 = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3,stride=3))\n",
    "        # 3 x 256\n",
    "        self.conv10 = nn.Sequential(\n",
    "            nn.Conv1d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3,stride=3))\n",
    "        # 1 x 512 \n",
    "        self.conv11 = nn.Sequential(\n",
    "            nn.Conv1d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.35))\n",
    "        # 2 x 512 \n",
    "        self.fc = nn.Linear(1024, 3)\n",
    "        self.activation = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # input x : 23 x 59049 x 1\n",
    "        # expected conv1d input : minibatch_size x num_channel x width\n",
    "\n",
    "        x = x.view(x.shape[0], 1,-1)\n",
    "#         print(x[0].dtype,\"here\")\n",
    "#         print(x.dtype)\n",
    "        # x : 23 x 1 x 59049\n",
    "#         x = x.double()\n",
    "#         print(type(x))\n",
    "        out = self.conv1(x)\n",
    "#         print(out.shape)\n",
    "        out = self.conv2(out)\n",
    "#         print(out.shape)\n",
    "        out = self.conv3(out)\n",
    "#         print(out.shape)\n",
    "        out = self.conv4(out)\n",
    "#         print(out.shape)\n",
    "        out = self.conv5(out)\n",
    "#         print(out.shape)\n",
    "        out = self.conv6(out)\n",
    "#         print(out.shape,\"on _ 6\")\n",
    "#         out = self.conv7(out)\n",
    "#         out = self.conv8(out)\n",
    "#         out = self.conv9(out)\n",
    "        out = self.conv10(out)\n",
    "#         print(out.shape,\"on _ 10\")\n",
    "        out = self.conv11(out) \n",
    "#         print(out.shape,\"on _ 11\")\n",
    "        \n",
    "        out = out.view(x.shape[0], out.size(1) * out.size(2))\n",
    "        logit = self.fc(out)\n",
    "\n",
    "        #logit = self.activation(logit)\n",
    "\n",
    "        return logit\n",
    "    start = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2116c08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device=torch.device('cpu')\n",
    "X_train = torch.from_numpy(X_train).double()\n",
    "X_train =X_train.to(device)\n",
    "# X_train = X_train.transpose(1,2).float() \n",
    "#input is (N, Cin, Lin) = Ntimesteps, Nfeatures, 128\n",
    "y_train = torch.from_numpy(y_train).double()\n",
    "y_train =y_train.to(device)\n",
    "X_test = torch.from_numpy(X_test)\n",
    "X_test =X_test.to(device)\n",
    "# X_test = X_test.transpose(1,2).float()\n",
    "y_test = torch.from_numpy(y_test).double()\n",
    "y_test =y_test.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa975ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FBGCNN()\n",
    "model = model.double()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.000001)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.000000008)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0000001, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1)\n",
    "#->lr=0.000000008 No Improvement\n",
    "#Epoch [50/100], Train Loss: 1.5672, Train Acc: 8.06%, Val Loss: 1.2213, Val Acc: 5.21%\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d366d329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orginal \n",
    "# model = FBGCNN()\n",
    "# model = model.double()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# # optimizer = torch.optim.Adam(model.parameters(), lr=0.000001)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.000000008)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)\n",
    "\n",
    "#Change 1 \n",
    "#->lr=0.000000008 / 100 Epoch\n",
    "#Epoch [50/100], Train Loss: 1.5672, Train Acc: 8.06%, Val Loss: 1.2213, Val Acc: 5.21%\n",
    "\n",
    "#Change 2\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c64c250",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.to(device)\n",
    "# X_train.shape\n",
    "# print(type(X_train))\n",
    "print(X_train.shape)\n",
    "# X_train=X_train.to(device)\n",
    "output= model(X_train)\n",
    "#print(X_train[0][0].dtype)\n",
    "#print(output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bd9543",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=42)\n",
    "\n",
    "num_epochs = 100\n",
    "batch_size = 62\n",
    "total_step = len(X_train)\n",
    "\n",
    "# Define lists to store the loss and accuracy for both training and validation\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "acc_list_epoch = []\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "train_acc_list = []\n",
    "val_acc_list = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Ensure the model is in training mode\n",
    "\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for i in range(int(np.floor(total_step/batch_size))):  # split data into batches\n",
    "        X_train_seg = X_train[i*batch_size:(i+1)*batch_size]\n",
    "        y_train_seg = y_train[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "        # Run the forward pass\n",
    "        outputs = model(X_train_seg)\n",
    "        loss = criterion(outputs, torch.max(y_train_seg, 1)[1])\n",
    "        train_loss += loss.item()\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        # Backprop and perform Adam optimisation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track the accuracy\n",
    "        total = X_train.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        _, actual = torch.max(y_train_seg, 1)\n",
    "        train_total += y_train_seg.size(0)\n",
    "        train_correct += (predicted == actual).sum().item()\n",
    "        acc_list.append(train_correct / total)\n",
    "\n",
    "    train_acc = 100 * train_correct / train_total\n",
    "    train_loss_list.append(train_loss/int(np.floor(total_step/batch_size)))\n",
    "    train_acc_list.append(train_acc)\n",
    "\n",
    "    model.eval()  # Ensure the model is in evaluation mode\n",
    "\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(int(np.floor(len(X_val)/batch_size))):  # split data into batches\n",
    "            X_val_seg = X_val[i*batch_size:(i+1)*batch_size]\n",
    "            y_val_seg = y_val[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "            # Run the forward pass\n",
    "            outputs = model(X_val_seg)\n",
    "            loss = criterion(outputs, torch.max(y_val_seg, 1)[1])\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Track the accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            _, actual = torch.max(y_val_seg, 1)\n",
    "            val_total += y_val_seg.size(0)\n",
    "            val_correct += (predicted == actual).sum().item()\n",
    "\n",
    "    val_acc = 100 * val_correct / val_total\n",
    "    val_loss_list.append(val_loss/int(np.floor(len(X_val)/batch_size)))\n",
    "    val_acc_list.append(val_acc)\n",
    "\n",
    "    print('Epoch [{}/{}], Train Loss: {:.4f}, Train Acc: {:.2f}%, Val Loss: {:.4f}, Val Acc: {:.2f}%'\n",
    "          .format(epoch+1, num_epochs, train_loss/int(np.floor(total_step/batch_size)), train_acc,\n",
    "                  val_loss/int(np.floor(len(X_val)/batch_size)), val_acc))\n",
    "    #acc_list_epoch.append(correct_sum/int(np.floor(total_step/batch_size)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95a0353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_loss_list, label='Training Loss')\n",
    "plt.plot(val_loss_list, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "\n",
    "# Plot the training and validation accuracy\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_acc_list, label='Training Accuracy')\n",
    "plt.plot(val_acc_list, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922f9b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot for Training Loss\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(loss_list, color='blue', linewidth=2, label='Training Loss')\n",
    "plt.title('Training Loss', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.grid(True, linestyle='dotted')\n",
    "plt.legend(fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot for Training Accuracy\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_acc_list, color='red', linewidth=2, label='Training Accuracy')\n",
    "plt.title('Training Accuracy', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.grid(True, linestyle='dotted')\n",
    "plt.legend(fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54d5938",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=pd.read_csv(r'C:\\Users\\Admin\\Desktop\\Notepad\\Data\\Test1.csv')\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf4b30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred=pred.iloc[:,:-3]\n",
    "Y_pred=pred.iloc[:,-3:]\n",
    "\n",
    "x_pred, y_pred = X_pred.values, Y_pred.values\n",
    "\n",
    "# scaling values for model\n",
    "x_pred_scale = MinMaxScaler()\n",
    "y_pred_scale = MinMaxScaler()\n",
    "\n",
    "Xx__pred = x_pred_scale.fit_transform(x_pred)\n",
    "Yy_pred = y_pred_scale.fit_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0695fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_x = np.reshape(Xx__pred, (Xx__pred.shape[0], 1, Xx__pred.shape[1])) \n",
    "pred_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d23149",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "start = timer()\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Convert the data to a PyTorch tensor and also convert it to Double\n",
    "Xx__pred_tensor = torch.from_numpy(Xx__pred).double()  # use .double() instead of .float()\n",
    "\n",
    "# Predictions need to be performed within a no_grad context when we're doing evaluation\n",
    "with torch.no_grad():\n",
    "    # Pass the data through the model\n",
    "    raw_outputs = model(Xx__pred_tensor)\n",
    "    # Convert the raw outputs to probabilities using the softmax function\n",
    "    predictions = torch.nn.functional.softmax(raw_outputs, dim=1)\n",
    "\n",
    "# Convert the predictions back to a numpy array\n",
    "predictions_np = predictions.numpy()\n",
    "\n",
    "duration = timer() - start\n",
    "print('Compilation Time:',duration)\n",
    "\n",
    "# Apply the inverse transformation to the predictions\n",
    "predictions_trans=y_scale.inverse_transform(predictions_np)\n",
    "print('The predicted central wavelength value of FBGs',predictions_trans)\n",
    "allFBG=predictions_trans[0]\n",
    "FBG1_CDNN=allFBG[0]\n",
    "FBG2_CDNN=allFBG[1]\n",
    "FBG3_CDNN=allFBG[2]\n",
    "\n",
    "FBG1_CDNN,FBG2_CDNN,FBG3_CDNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196dadb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Actual Value\n",
    "y_pred\n",
    "\n",
    "allFBG_act=y_pred[0]\n",
    "FBG1_act_CDNN=allFBG_act[0]\n",
    "FBG2_act_CDNN=allFBG_act[1]\n",
    "FBG3_act_CDNN=allFBG_act[2]\n",
    "\n",
    "print(\"the actual value are:\",FBG1_act_CDNN,FBG2_act_CDNN,FBG3_act_CDNN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d546c55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Square Error between the predicted and the actual value\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "print('Mean squared error:',mean_squared_error(y_pred,predictions_trans))\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(Y_pred, predictions_trans))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(Y_pred, predictions_trans)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60b75ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual vs predicted wavelength\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#x = np.linspace(1544.95,1549.95,1001);\n",
    "x = np.linspace(1540,1550,2001);\n",
    "\n",
    "FBG1_act=1*np.exp(-4*np.log(2)*((x-FBG1_act_CDNN)/(0.2))**2); #Actual central wavelength of FBg1\n",
    "FBG2_act=0.94*np.exp(-4*np.log(2)*((x-FBG2_act_CDNN)/(0.2))**2);#Actual central wavelength of FBg2\n",
    "FBG3_act=0.54*np.exp(-4*np.log(2)*((x-FBG3_act_CDNN)/(0.2))**2); #Actual central wavelength of FBg3\n",
    "#FBG4_act=0.23*np.exp(-4*np.log(2)*((x-FBG4_act_MLP)/(0.2))**2); #Actual central wavelength of FBg4\n",
    "FBG1_pred=1*np.exp(-4*np.log(2)*((x-FBG1_CDNN)/(0.2))**2); #FBG1 Pridcited central wavelength\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(x,FBG1_act,label='Actual value of FBG1',linewidth=4, color='r')\n",
    "plt.ylabel('Power(a.u.)', fontweight='bold', color = 'black', fontsize='12', horizontalalignment='center')\n",
    "plt.xlabel('wavelength(nm)', fontweight='bold', color = 'black', fontsize='12', horizontalalignment='center')\n",
    "plt.plot(x,FBG1_pred,label='Predicted value of FBG1',linewidth=3, color='b')\n",
    "#plt.legend(loc='best')\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.2, 1))\n",
    "\n",
    "plt.tick_params(\n",
    "    axis='y',          # changes apply to the x-axis\n",
    "    which='major',      # both major and minor ticks are affected\n",
    "    left='on',      # ticks along the bottom edge are off\n",
    "    labelleft='off') # labels along the bottom edge are off\n",
    "\n",
    "plt.xticks.labelsize:'100'\n",
    "plt.yticks.labelsize:'100'\n",
    "plt.grid(linestyle='dotted',linewidth=1);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b73155",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#x = np.linspace(1544.95,1549.95,1001);\n",
    "x = np.linspace(1540,1550,2001);\n",
    "\n",
    "FBG1_act=1*np.exp(-4*np.log(2)*((x-FBG1_act_CDNN)/(0.2))**2); #Actual central wavelength of FBg1\n",
    "FBG2_act=0.94*np.exp(-4*np.log(2)*((x-FBG2_act_CDNN)/(0.2))**2);#Actual central wavelength of FBg2\n",
    "FBG3_act=0.54*np.exp(-4*np.log(2)*((x-FBG3_act_CDNN)/(0.2))**2); #Actual central wavelength of FBg3\n",
    "# FBG4_act=0.23*np.exp(-4*np.log(2)*((x-FBG1_act_MLP)/(0.2))**2); #Actual central wavelength of FBg4\n",
    "FBG1_pred=1*np.exp(-4*np.log(2)*((x-FBG1_CDNN)/(0.2))**2); #FBG1 Pridcited central wavelength\n",
    "FBG2_pred=0.94*np.exp(-4*np.log(2)*((x-FBG2_CDNN)/(0.2))**2); #FBG1 Pridcited central wavelength\n",
    "FBG3_pred=0.54*np.exp(-4*np.log(2)*((x-FBG3_CDNN)/(0.2))**2);\n",
    "\n",
    "overlap=FBG1_act+FBG2_act;#overlap spectra of FBG1 and FBG2\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(x,FBG1_pred,label='Predicted value of FBG1',linewidth=4, color='r')\n",
    "plt.ylabel('Power(a.u.)', fontweight='bold', color = 'black', fontsize='12', horizontalalignment='center')\n",
    "plt.xlabel('wavelength(nm)', fontweight='bold', color = 'black', fontsize='12', horizontalalignment='center')\n",
    "plt.plot(x,FBG2_pred,label='Predicted value of FBG2',linewidth=3, color='b')\n",
    "plt.plot(x,FBG3_pred,label='Predicted value of FBG3',linewidth=3, color='y')\n",
    "plt.plot(x,overlap,'--',label='overlap spectra of FBG1 & FBG2',linewidth=3, color='black')\n",
    "#plt.legend(loc='best')\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.15, 1))\n",
    "\n",
    "plt.tick_params(\n",
    "    axis='y',          # changes apply to the x-axis\n",
    "    which='major',      # both major and minor ticks are affected\n",
    "    left='on',      # ticks along the bottom edge are off\n",
    "    labelleft='off') # labels along the bottom edge are off\n",
    "\n",
    "plt.xticks.labelsize:'100'\n",
    "plt.yticks.labelsize:'100'\n",
    "plt.grid(linestyle='dotted', linewidth=1);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd3e2f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Displaying TECH 1\n",
    "\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# #x = np.linspace(1544.95,1549.95,1001);\n",
    "# x = np.linspace(1540,1550,2001);\n",
    "\n",
    "# FBG1_act=1*np.exp(-4*np.log(2)*((x-FBG1_act_CDNN)/(0.2))**2); #Actual central wavelength of FBg1\n",
    "# FBG2_act=0.94*np.exp(-4*np.log(2)*((x-FBG2_act_CDNN)/(0.2))**2);#Actual central wavelength of FBg2\n",
    "# FBG3_act=0.54*np.exp(-4*np.log(2)*((x-FBG3_act_CDNN)/(0.2))**2); #Actual central wavelength of FBg3\n",
    "# FBG1_pred=1*np.exp(-4*np.log(2)*((x-FBG1_CDNN)/(0.2))**2); #FBG1 Pridcited central wavelength\n",
    "# FBG2_pred=0.94*np.exp(-4*np.log(2)*((x-FBG1_CDNN)/(0.2))**2); #FBG1 Pridcited central wavelength\n",
    "\n",
    "# overlap=FBG1_act+FBG2_act;#overlap spectra of FBG1 and FBG2\n",
    "\n",
    "# # Make the plot look attractive\n",
    "# plt.style.use('seaborn-darkgrid')\n",
    "\n",
    "# plt.figure(figsize=(8,6))\n",
    "\n",
    "# plt.plot(x,FBG1_pred,label='Predicted value of FBG1',linewidth=2, color='r')\n",
    "# plt.plot(x,FBG2_pred,label='Predicted value of FBG2',linewidth=2, color='b')\n",
    "# plt.plot(x,overlap,'--',label='overlap spectra of FBG1 & FBG2',linewidth=2, color='black')\n",
    "\n",
    "# plt.ylabel('Power(a.u.)', fontweight='bold', color = 'black', fontsize='14', horizontalalignment='center')\n",
    "# plt.xlabel('wavelength(nm)', fontweight='bold', color = 'black', fontsize='14', horizontalalignment='center')\n",
    "\n",
    "# plt.legend(loc='upper right', bbox_to_anchor=(1.15, 1), fontsize='12')\n",
    "\n",
    "# plt.tick_params(\n",
    "#     axis='y',          \n",
    "#     which='both',      \n",
    "#     left=False,      \n",
    "#     labelleft=False) \n",
    "\n",
    "# plt.xticks(fontsize=12)\n",
    "# plt.yticks([])\n",
    "\n",
    "# plt.grid(linestyle='dotted', linewidth=1);\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2c60c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Displaying TECH 3\n",
    "\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# sns.set_style(\"whitegrid\")\n",
    "\n",
    "# #x = np.linspace(1544.95,1549.95,1001);\n",
    "# x = np.linspace(1540,1550,2001);\n",
    "\n",
    "# FBG1_act=1*np.exp(-4*np.log(2)*((x-FBG1_act_CDNN)/(0.2))**2); #Actual central wavelength of FBg1\n",
    "# FBG2_act=0.94*np.exp(-4*np.log(2)*((x-FBG2_act_CDNN)/(0.2))**2);#Actual central wavelength of FBg2\n",
    "# FBG3_act=0.54*np.exp(-4*np.log(2)*((x-FBG3_act_CDNN)/(0.2))**2); #Actual central wavelength of FBg3\n",
    "# # FBG4_act=0.23*np.exp(-4*np.log(2)*((x-FBG1_act_MLP)/(0.2))**2); #Actual central wavelength of FBg4\n",
    "# FBG1_pred=1*np.exp(-4*np.log(2)*((x-FBG1_CDNN)/(0.2))**2); #FBG1 Pridcited central wavelength\n",
    "# FBG2_pred=0.94*np.exp(-4*np.log(2)*((x-FBG1_CDNN)/(0.2))**2); #FBG1 Pridcited central wavelength\n",
    "\n",
    "# overlap=FBG1_act+FBG2_act;#overlap spectra of FBG1 and FBG2\n",
    "\n",
    "# plt.figure(figsize=(10,8))\n",
    "# plt.plot(x,FBG1_pred,label='Predicted value of FBG1',linewidth=2, color='red')\n",
    "# plt.plot(x,FBG2_pred,label='Predicted value of FBG2',linewidth=2, color='blue')\n",
    "# plt.plot(x,overlap,'--',label='Overlap spectra of FBG1 & FBG2',linewidth=2, color='black')\n",
    "\n",
    "# plt.ylabel('Power(a.u.)', fontweight='bold', fontsize='14', color = 'black')\n",
    "# plt.xlabel('Wavelength(nm)', fontweight='bold', fontsize='14', color = 'black')\n",
    "\n",
    "# plt.legend(loc='upper right', bbox_to_anchor=(1.15, 1), fontsize='12')\n",
    "\n",
    "# plt.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)\n",
    "\n",
    "# plt.xticks(fontsize='12')\n",
    "# plt.yticks([])\n",
    "\n",
    "# plt.grid(linestyle='dotted', linewidth=1);\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0627c81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Displaying TECH 33\n",
    "\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# sns.set_style(\"whitegrid\")\n",
    "\n",
    "# #x = np.linspace(1544.95,1549.95,1001);\n",
    "# x = np.linspace(1540,1550,2001);\n",
    "\n",
    "# FBG1_act=1*np.exp(-4*np.log(2)*((x-FBG1_act_CDNN)/(0.2))**2); #Actual central wavelength of FBg1\n",
    "# FBG2_act=0.94*np.exp(-4*np.log(2)*((x-FBG2_act_CDNN)/(0.2))**2);#Actual central wavelength of FBg2\n",
    "# FBG3_act=0.54*np.exp(-4*np.log(2)*((x-FBG3_act_CDNN)/(0.2))**2); #Actual central wavelength of FBg3\n",
    "# # FBG4_act=0.23*np.exp(-4*np.log(2)*((x-FBG1_act_MLP)/(0.2))**2); #Actual central wavelength of FBg4\n",
    "# FBG1_pred=1*np.exp(-4*np.log(2)*((x-FBG1_CDNN)/(0.2))**2); #FBG1 Pridcited central wavelength\n",
    "# FBG2_pred=0.94*np.exp(-4*np.log(2)*((x-FBG1_CDNN)/(0.2))**2); #FBG1 Pridcited central wavelength\n",
    "\n",
    "# overlap=FBG1_act+FBG2_act;#overlap spectra of FBG1 and FBG2\n",
    "\n",
    "# plt.figure(figsize=(10,8))\n",
    "# plt.plot(x,FBG1_pred,label='Predicted value of FBG1',linewidth=2, color='purple')\n",
    "# plt.plot(x,FBG2_pred,label='Predicted value of FBG2',linewidth=2, color='green')\n",
    "# plt.plot(x,overlap,'--',label='Overlap spectra of FBG1 & FBG2',linewidth=2, color='orange')\n",
    "\n",
    "# plt.ylabel('Power(a.u.)', fontweight='bold', fontsize='14', color = 'black')\n",
    "# plt.xlabel('Wavelength(nm)', fontweight='bold', fontsize='14', color = 'black')\n",
    "\n",
    "# plt.legend(loc='upper right', bbox_to_anchor=(1.15, 1), fontsize='12')\n",
    "\n",
    "# plt.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)\n",
    "\n",
    "# plt.xticks(fontsize='12')\n",
    "# plt.yticks([])\n",
    "\n",
    "# plt.grid(linestyle='dotted', linewidth=1);\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8977fc7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
